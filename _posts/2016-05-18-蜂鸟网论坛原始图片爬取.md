---
layout: post
title:  "蜂鸟网论坛原始图片爬取"
date:   2016-05-18 15:14:54
categories: 爬虫
tags: python 我的项目 爬虫
author: 张云浩
---

## 前言:

​	自己比较喜欢摄影，经常看论坛别人的分享。发现保存图片很麻烦，就自己做了一个工具。很久以前做基于python的简易的图片爬虫，目的是获得蜂鸟论坛的帖子图片。

​	GitHub地址：[https://github.com/ZYunH/FengNiao_Downloader](https://github.com/ZYunH/FengNiao_Downloader)

​	上面有win7 32bit打包后的程序，可直接使用。说明请查看readme。



## 思路

​	1.获得帖子地址

​	2.解析content，获取一键看图的链接

​	3.将一键看图的每一页中原始图片地址保存，自动换页

​	4.下载图片。因为服务器返回经常出问题，故这里需设置自动重新下载。



## 代码

```python
# -*- coding:utf-8 -*-
import urllib2
import urllib
import cookielib
import re
import os

"""
fengniao_photodown.py
​~~~~~~~~~~~~~~~~~~~~~~~
Author: ZhangYunHao
Version:1.1
"""


def url_read(url, timeout=5):
	request = urllib2.Request(url)

	cj = cookielib.LWPCookieJar()
	cookie_support = urllib2.HTTPCookieProcessor(cj)
	opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)
	urllib2.install_opener(opener)

	try:
		response = opener.open(request, timeout=timeout)
	except urllib2.URLError, e:
		print 'url_read() error!'
		print e
		return 'Error'

	result = response.read()

	return result


def auto_down(url, filename):
	try:
		urllib.urlretrieve(url, filename)
	except urllib.ContentTooShortError:
		print 'Network conditions is not good.Reloading.'
		auto_down(url, filename)


def fengniao_photo_down(url_original):
	# Module1: get original url
	# url_original = 'http://bbs.fengniao.com/forum/8771920.html'

	# Module2: get 'gopicture' url
	url_original_content = url_read(url_original)

	pattern_gopicture = '<a href="(/forum/pic/.+?\.html)" class="goPicture"'

	url_gopicture = re.findall(pattern_gopicture, url_original_content)

	url_gopicture = 'http://bbs.fengniao.com' + url_gopicture[0]

	# Module3: get 'gopicture' content ,and get photos url,then,move to next web
	photo_url_list = []

	while url_gopicture:

		url_gopicture_content = url_read(url_gopicture)

		pattern_gopicture_photo = '<a href="(http://img3.fengniao.com/forum/attachpics/.+?\.jpg)" class="pictureDownload"'

		photo_url = re.findall(pattern_gopicture_photo, url_gopicture_content)

		photo_url_list.append(photo_url)

		pattern_gopicture_nextweb = '<div class="pictureAreaR" next-url="(/forum/pic/.+?\.html)">'

		url_nextweb = re.findall(pattern_gopicture_nextweb, url_gopicture_content)

		try:
			url_nextweb = 'http://bbs.fengniao.com' + url_nextweb[0]
		except IndexError:
			break

		url_gopicture = url_nextweb

	# Module4: download photos from photp_url_list
	filename = os.getcwd() + '/' + url_original[30:37] + '/'

	try:
		os.mkdir('%s' % filename)
	except OSError:
		pass

	for i in range(len(photo_url_list)):
		print 'Downloading %s/%s photo ' % (i + 1, len(photo_url_list))
		if os.path.exists(filename + '%s.jpg' % (i + 1)):
			pass
		else:
			auto_down(photo_url_list[i][0], filename + '%s.jpg' % (i + 1))
		if i == (len(photo_url_list) - 1):
			print 'Download finished!Altogether %s photos!' % (i + 1)
			print 'Download completed, thank you for use,you can find me via qq:3358023393 (new number).Author:zhangyunhao'


print (
	'Input format:(http://bbs.fengniao.com/forum/8821215.html) or (8821215),reasonable input in brackets,Author:ZhangYunHao')

user_input = raw_input('Please enter a URL that you need to get the picture:')

if len(str(user_input)) == 7:
	url = 'http://bbs.fengniao.com/forum/%s.html' % user_input
else:
	url = user_input

fengniao_photo_down(url)
```



## 后续

​	1.可以利用上面的下载函数，爬大量的图片。

​	2.代码逻辑、风格太差，但是勉强能用，就懒得修改了。